# ImageSearch

Uses a HuggingFace sentence transformer with the "clip-ViT-B-32" model to generate vector embeddings based on images. Once the data is in RAM, the embeddings are stored in DataStax Astra DB.

Standalone Java implementation of the [Image Search with CLIP](https://colab.research.google.com/github/awesome-astra/docs/blob/main/docs/pages/tools/notebooks/astra_vsearch_image.ipynb) found in DataStax's documentation.

Not quite complete.